{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169575b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HADOOP_CONF_DIR'] = '/etc/hadoop/conf'\n",
    "os.environ['YARN_CONF_DIR'] = '/etc/hadoop/conf'\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import datetime\n",
    "import pyspark.sql.functions as F \n",
    "import dateutil.relativedelta\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "            .master(\"yarn\") \\\n",
    "            .appName(\"akk_2\") \\\n",
    "            .config(\"spark.executor.memory\", \"5530m\")\\\n",
    "            .config(\"spark.executor.instances\", 4)\\\n",
    "            .config(\"spark.executor.cores\", 2)\\\n",
    "            .config(\"spark.files.overwrite\",True)\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd77af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_verified = spark.read.parquet('/user/master/data/snapshots/tags_verified/actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec4ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def input_paths(date,depth):\n",
    "#     range_ = []\n",
    "#     date = datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "#     i = 0\n",
    "#     while i < depth:\n",
    "#         date_2 = date - dateutil.relativedelta.relativedelta(days=i)\n",
    "#         path_ = f'/user/andrew_0/data/events/date={date_2.strftime(\"%Y-%m-%d\")}/event_type=message'\n",
    "#         range_.append(path_)\n",
    "#         i = i+1\n",
    "#     return(range_)\n",
    "\n",
    "\n",
    "# range_ = input_paths(date_from,depth)\n",
    "\n",
    "# df = spark.read.parquet(*range_)\n",
    "\n",
    "# df_explode = df.withColumn(\"tag\", F.explode(df.event.tags)).where(\"event.message_channel_to is not null\")\n",
    "# df_explode = df_explode.select(df_explode.event.message_from.alias(\"message_from\"),df_explode.tag)\n",
    "\n",
    "# df_explode = df_explode.groupBy('tag') \\\n",
    "#                       .agg(F.countDistinct('message_from').alias(\"suggested_count\")) \\\n",
    "#                       .filter(F.col('suggested_count') >= 100) \\\n",
    "#                       .orderBy(F.col(\"suggested_count\").desc()) \\\n",
    "#                       .join(tags_verified, ['tag'], how='left_anti')\n",
    "\n",
    "# df_explode.write.format('parquet').save('/user/andrew0/data/analytics/candidates_d84_pyspark',mode='overwrite')\n",
    "\n",
    "# df_7 = spark.read.parquet('/user/andrew0/data/analytics/candidates_d7_pyspark')\n",
    "# df_7.describe().show()\n",
    "\n",
    "# df_84 = spark.read.parquet('/user/andrew0/data/analytics/candidates_d84_pyspark')\n",
    "# df_84.describe().show()\n",
    "\n",
    "\n",
    "\n",
    "# def input_paths(date, depth):\n",
    "#     dt = datetime.datetime.strptime(date, '%Y-%m-%d')\n",
    "#     return [f\"/user/username/data/events/date={(dt-datetime.timedelta(days=x)).strftime('%Y-%m-%d')}/event_type=message\" for x in range(depth)]\n",
    "\n",
    "# paths = input_paths('2022-05-31', M)\n",
    "# messages = spark.read.parquet(*paths)\n",
    "# all_tags = messages.where(\"event.message_channel_to is not null\").selectExpr([\"event.message_from as user\", \"explode(event.tags) as tag\"]).groupBy(\"tag\").agg(F.expr(\"count(distinct user) as suggested_count\")).where(\"suggested_count >= 100\")\n",
    "# verified_tags = spark.read.parquet(\"/user/master/data/snapshots/tags_verified/actual\")\n",
    "# candidates = all_tags.join(verified_tags, \"tag\", \"left_anti\")\n",
    "\n",
    "# candidates.write.parquet(f'/user/username/data/analytics/candidates_d{M}_pyspark')\n",
    "\n",
    "# /usr/lib/spark/bin/spark-submit --master yarn --deploy-mode cluster verified_tags_candidates.py 2022-05-31 5 300 \n",
    "\n",
    "# /user/andrew0/5.2.4/analytics/verified_tags_candidates_d5/date=2022-05-31\n",
    "\n",
    "# date_from = '2022-05-31'\n",
    "# depth = 5\n",
    "# sugested_users = 300\n",
    "# input_path = '/user/andrew_0/data/events'\n",
    "# tags_verified_path = '/user/master/data/snapshots/tags_verified/actual'\n",
    "# output_path = '/user/andrew0/5.2.4/analytics/verified_tags_candidates_d5/'+'date='+date_from\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac8461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interests_d7_eth =  spark.read.parquet('/user/examples/data/interests_d7')\n",
    "# interests_d7_eth.show(10,False)\n",
    "# interests_d28_eth = spark.read.parquet('/user/examples/data/interests_d28')\n",
    "# interests_d28_eth.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27e6d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_from = '2022-06-04'\n",
    "depth = 5\n",
    "# sugested_users = 300\n",
    "input_path = '/user/andrew_0/data/events'\n",
    "# tags_verified_path = '/user/master/data/snapshots/tags_verified/actual'\n",
    "# output_path = '/user/andrew0/5.2.4/analytics/verified_tags_candidates_d5/'+'date='+date_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64210059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# range_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82e5e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_paths(date,depth):\n",
    "    range_ = []\n",
    "    date = datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    i = 0\n",
    "    while i < depth:\n",
    "        date_2 = date - dateutil.relativedelta.relativedelta(days=i)\n",
    "        path_ = f'{input_path}/date={date_2.strftime(\"%Y-%m-%d\")}/event_type=message'\n",
    "        range_.append(path_)\n",
    "        i = i+1\n",
    "    return(range_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaaf91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_ = input_paths(date_from,depth)\n",
    "\n",
    "df = spark.read.parquet(*range_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11fab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "window_  = Window.partitionBy([\"user\"]).orderBy(F.col(\"suggested_count\").desc(),F.col(\"tag\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1439f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_tops(date_from,depth,spark):\n",
    "    \n",
    "    range_ = input_paths(date_from,depth)\n",
    "    \n",
    "    df = spark.read.parquet(*range_)\n",
    "    \n",
    "    window_  = Window.partitionBy([\"user\"]).orderBy(F.col(\"suggested_count\").desc(),F.col(\"tag\").desc())\n",
    "    \n",
    "    \n",
    "    df = df.where(\"event.message_channel_to is not null\")\\\n",
    "    .select([F.col(\"event.message_from\").alias(\"user\"), F.explode(F.col(\"event.tags\")).alias(\"tag\")])\\\n",
    "    .groupBy([\"user\",\"tag\"]).agg(F.count(\"tag\").alias(\"suggested_count\"))\\\n",
    "    .withColumn(\"r_n\",F.row_number().over(window_))\\\n",
    "    .withColumn(\"tag_top_1\",F.lead(\"tag\",0).over(window_))\\\n",
    "    .withColumn(\"tag_top_2\",F.lead(\"tag\",1).over(window_))\\\n",
    "    .withColumn(\"tag_top_3\",F.lead(\"tag\",2).over(window_))\\\n",
    "    .where(\"r_n = 1\")\\\n",
    "    .select([F.col('user').alias('user_id'),F.col('tag_top_1'),F.col('tag_top_2'),F.col('tag_top_3')])\n",
    "    \n",
    "    print(date_from,depth)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aebbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_tops('2022-06-04', 5, spark).repartition(1).write.parquet('/user/andrew0/data/tmp/tag_tops_06_04_5')\n",
    "\n",
    "tag_tops('2022-05-04', 5, spark).repartition(1).write.parquet('/user/andrew0/data/tmp/tag_tops_05_04_5')\n",
    "\n",
    "tag_tops('2022-05-04', 1, spark).repartition(1).write.parquet('/user/andrew0/data/tmp/tag_tops_05_04_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcf5dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.parquet('/user/andrew0/data/tmp/tag_tops_06_04_5').show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b8e14a",
   "metadata": {},
   "source": [
    "### reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1edf7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_from = '2022-04-04'\n",
    "depth = 1\n",
    "input_path = '/user/andrew_0/data/events'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "14dfb08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_paths(date,depth,event_type):\n",
    "    range_ = []\n",
    "    date = datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    i = 0\n",
    "    while i < depth:\n",
    "        date_2 = date - dateutil.relativedelta.relativedelta(days=i)\n",
    "        path_ = f'{input_path}/date={date_2.strftime(\"%Y-%m-%d\")}/event_type={event_type}'\n",
    "        range_.append(path_)\n",
    "        i = i+1\n",
    "    return(range_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "17a4525d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- message_id: long (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- message_id: long (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- reaction_type: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- message_id: long (nullable = true)\n",
      " |-- tag: string (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- reaction_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# def tag_tops(date_from,depth,spark):\n",
    "    \n",
    "range_message = input_paths(date_from,depth,'message')\n",
    "range_reaction = input_paths(date_from,depth,'reaction')\n",
    "\n",
    "df_message = spark.read.parquet(*range_message)\n",
    "df_message = df_message.select(F.col(\"event.*\")).where(\"tags is not null\")\n",
    "df_message = df_message.select([F.col('message_id'),F.explode(F.col(\"tags\")).alias(\"tag\")])\n",
    "\n",
    "df_reaction = spark.read.parquet(*range_reaction)\n",
    "df_reaction = df_reaction.select(F.col(\"event.*\")).where(\"reaction_type is not null\")\n",
    "df_reaction = df_reaction.select([F.col('message_id'),F.col(\"reaction_from\").alias(\"user\"),F.col(\"reaction_type\")])\n",
    "\n",
    "df = df_message.join(df_reaction,df_message.message_id ==  df_reaction.message_id,\"inner\").drop(df_reaction.message_id)\n",
    "\n",
    "df_message.printSchema()\n",
    "df_reaction.printSchema()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e44784a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "window_  = Window.partitionBy([\"user\"]).orderBy(F.col(\"reaction_count\").desc(),F.col(\"tag\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3673cef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 109:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+------+-------------+\n",
      "|message_id|tag|user  |reaction_type|\n",
      "+----------+---+------+-------------+\n",
      "|1106403   |PHP|117765|dislike      |\n",
      "|1106403   |PHP|76913 |like         |\n",
      "|1106403   |PHP|136616|like         |\n",
      "|1106403   |PHP|73185 |like         |\n",
      "|1106403   |PHP|121920|dislike      |\n",
      "|1106403   |PHP|8116  |like         |\n",
      "|1106403   |PHP|101751|like         |\n",
      "|1106403   |PHP|49172 |like         |\n",
      "|1106403   |CSS|117765|dislike      |\n",
      "|1106403   |CSS|76913 |like         |\n",
      "+----------+---+------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "051b7890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+-------------+--------------+---+-----------------+-----------------+\n",
      "|user  |tag              |reaction_type|reaction_count|r_n|like_tag_top_1   |like_tag_top_2   |\n",
      "+------+-----------------+-------------+--------------+---+-----------------+-----------------+\n",
      "|136082|Физика           |like         |2             |1  |Физика           |Научно-популярное|\n",
      "|136082|Научно-популярное|like         |2             |2  |Научно-популярное|Лазеры           |\n",
      "|136082|Лазеры           |like         |1             |3  |Лазеры           |Космонавтика     |\n",
      "|136082|Космонавтика     |like         |1             |4  |Космонавтика     |votizen          |\n",
      "|136082|votizen          |like         |1             |5  |votizen          |techmeme         |\n",
      "|136082|techmeme         |like         |1             |6  |techmeme         |memeorandum      |\n",
      "|136082|memeorandum      |like         |1             |7  |memeorandum      |democracy        |\n",
      "|136082|democracy        |like         |1             |8  |democracy        |null             |\n",
      "+------+-----------------+-------------+--------------+---+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"user = 136082\")\\\n",
    ".groupBy([\"user\",\"tag\",\"reaction_type\"]).agg(F.count(\"message_id\").alias(\"reaction_count\"))\\\n",
    ".withColumn(\"r_n\",F.row_number().over(window_))\\\n",
    ".withColumn(\"like_tag_top_1\",F.lead(\"tag\",0).over(window_))\\\n",
    ".withColumn(\"like_tag_top_2\",F.lead(\"tag\",1).over(window_))\\\n",
    ".show(10,False)\n",
    "# .withColumn(\"tag_top_2\",F.lead(\"tag\",1).over(window_))\\\n",
    "# .withColumn(\"tag_top_3\",F.lead(\"tag\",2).over(window_))\\\n",
    "# .where(\"r_n = 1\")\\\n",
    "# .select([F.col('user').alias('user_id'),F.col('tag_top_1'),F.col('tag_top_2'),F.col('tag_top_3')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b3873e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
